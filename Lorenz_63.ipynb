{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBLNjxku64/kgAbNs/LGpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeusfire2058/code_stuff_woo/blob/master/Lorenz_63.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepxde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu1GWmO2ukpv",
        "outputId": "c92d1678-85df-45ee-ffb6-0168a0170599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepxde\n",
            "  Downloading deepxde-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from deepxde) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepxde) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from deepxde) (1.6.1)\n",
            "Collecting scikit-optimize>=0.9.0 (from deepxde)\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deepxde) (1.16.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize>=0.9.0->deepxde) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize>=0.9.0->deepxde)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize>=0.9.0->deepxde) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepxde) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepxde) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize>=0.9.0->deepxde) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->deepxde) (1.17.0)\n",
            "Downloading deepxde-1.14.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize, deepxde\n",
            "Successfully installed deepxde-1.14.0 pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4tKI8P75jhZO",
        "outputId": "194bd983-baf6-44bc-f18a-e3b560fbc858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation times from t=100.0 to 110.0 with 101 points\n",
            "Time between observations: 0.09999999999999432 (should be 0.1)\n",
            "Generating reference solution for initial condition 0/1000\n",
            "Generating reference solution for initial condition 100/1000\n",
            "Generating reference solution for initial condition 200/1000\n",
            "Generating reference solution for initial condition 300/1000\n",
            "Generating reference solution for initial condition 400/1000\n",
            "Generating reference solution for initial condition 500/1000\n",
            "Generating reference solution for initial condition 600/1000\n",
            "Generating reference solution for initial condition 700/1000\n",
            "Generating reference solution for initial condition 800/1000\n",
            "Generating reference solution for initial condition 900/1000\n",
            "\n",
            "=== Verification ===\n",
            "Number of initial conditions (Ns): 1000\n",
            "Observations per simulation: 100 (from 101 time points)\n",
            "Expected total samples: 100000 (Ns × 100)\n",
            "Actual input_data shape: (100000, 4) (should be (100000, 4))\n",
            "Actual output_data shape: (100000, 3) (should be (100000, 3))\n",
            "Compiling model...\n",
            "Building feed-forward neural network...\n",
            "'build' took 0.090209 s\n",
            "\n",
            "'compile' took 2.124513 s\n",
            "\n",
            "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
            "Training model...\n",
            "\n",
            "Step      Train loss    Test loss     Test metric   \n",
            "0         [2.61e+02]    [2.59e+02]    [9.94e-01]    \n",
            "Epoch 1: train loss improved from inf to 2.61e+02, saving model to ./codes/model-1.ckpt ...\n",
            "\n",
            "1000      [6.48e+00]    [6.44e+00]    [1.57e-01]    \n",
            "Epoch 1000: train loss improved from 2.61e+02 to 6.48e+00, saving model to ./codes/model-1000.ckpt ...\n",
            "\n",
            "\n",
            "Best model at step 1000:\n",
            "  train loss: 6.48e+00\n",
            "  test loss: 6.44e+00\n",
            "  test metric: [1.57e-01]\n",
            "\n",
            "'train' took 39.911056 s\n",
            "\n",
            "Generating reference solution 0/1\n",
            "Compiling model...\n",
            "Building feed-forward neural network...\n",
            "'build' took 0.073678 s\n",
            "\n",
            "'compile' took 5.882668 s\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'restore'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2076636482.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"l2 relative error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./codes/model-\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'restore'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import deepxde as dde\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.layers import TFSMLayer\n",
        "import os\n",
        "\n",
        "#time variable for linespace\n",
        "num_reference_solutions = 1000  # N_s\n",
        "total_simulation_time = 110  # Simulate up to t=110\n",
        "observation_start_time = 100  # Start recording observations at t=100\n",
        "observations_per_time_unit = 10  # δ = 0.1 time units between observations\n",
        "delta_t = 1.0/observations_per_time_unit  # 0.1\n",
        "\n",
        "# Create observation times (from 100 to 110, every 0.1 units)\n",
        "num_observations = int((total_simulation_time - observation_start_time) / delta_t) + 1\n",
        "observation_times = np.linspace(observation_start_time, total_simulation_time, num_observations)\n",
        "\n",
        "    # Full simulation times (from 0 to 110 - needed for the ODE solver)\n",
        "full_simulation_times = np.linspace(0, total_simulation_time,\n",
        "                                    int(total_simulation_time * observations_per_time_unit) + 1)\n",
        "\n",
        "\n",
        "class Lorenz63:\n",
        "    def __init__(self, sigma=10.0, rho=28.0, beta=8/3):\n",
        "        self.sigma = sigma\n",
        "        self.rho = rho\n",
        "        self.beta = beta\n",
        "\n",
        "    def original_system(self, state, t):\n",
        "        x, y, z = state\n",
        "\n",
        "        # system equations\n",
        "        dxdt = self.sigma * (y - x)\n",
        "        dydt = x * (self.rho - z) - y\n",
        "        dzdt = x * y - self.beta * z\n",
        "\n",
        "        return [dxdt, dydt, dzdt]\n",
        "\n",
        "    def nudged_system(self, state, t, x_observed, mu):\n",
        "        x_bar, y_bar, z_bar = state\n",
        "\n",
        "        # Get the observed x value at time t (needs interpolation)\n",
        "        x = np.interp(t, x_observed[:, 0], x_observed[:, 1])\n",
        "\n",
        "        # system equations\n",
        "        dxdt_bar = self.sigma * (y_bar - x_bar) - mu * (x_bar - x) # with nudging term!\n",
        "        dydt_bar = x_bar * (self.rho - z_bar) - y_bar\n",
        "        dzdt_bar = x_bar * y_bar - self.beta * z_bar\n",
        "\n",
        "        return [dxdt_bar, dydt_bar, dzdt_bar]\n",
        "#Make Training Data\n",
        "def simulate_lorenz_with_nudging():\n",
        "    # Parameters\n",
        "    sigma = 10.0\n",
        "    rho = 28.0\n",
        "    beta = 8/3\n",
        "    mu = 30  # Nudging parameter\n",
        "\n",
        "    num_reference_solutions = 1000  # N_s\n",
        "    total_simulation_time = 110  # Simulate up to t=110\n",
        "    observation_start_time = 100  # Start recording observations at t=100\n",
        "    observations_per_time_unit = 10  # δ = 0.1 time units between observations\n",
        "    delta_t = 1.0/observations_per_time_unit  # 0.1\n",
        "\n",
        "    # Create observation times (from 100 to 110, every 0.1 units)\n",
        "    num_observations = int((total_simulation_time - observation_start_time) / delta_t) + 1\n",
        "    observation_times = np.linspace(observation_start_time, total_simulation_time, num_observations)\n",
        "\n",
        "    # Verify observation times\n",
        "    print(f\"Observation times from t={observation_times[0]} to {observation_times[-1]} with {len(observation_times)} points\")\n",
        "    print(f\"Time between observations: {observation_times[1] - observation_times[0]} (should be {delta_t})\")\n",
        "\n",
        "    # Full simulation times (from 0 to 110 - needed for the ODE solver)\n",
        "    full_simulation_times = np.linspace(0, total_simulation_time,\n",
        "                                       int(total_simulation_time * observations_per_time_unit) + 1)\n",
        "\n",
        "    input_samples = [] # stores (x_bar, y_bar, z_bar, observed x) @ time t\n",
        "    output_samples = [] # stores (x_bar, y_bar, z_bar) @ time t+1\n",
        "\n",
        "    for i in range(num_reference_solutions):\n",
        "        # Display progress of generating solutions\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Generating reference solution for initial condition {i}/{num_reference_solutions}\")\n",
        "\n",
        "        # Generate random initial conditions from N(0, 10)\n",
        "        x0, y0, z0 = np.random.normal(loc=0, scale=10, size=3)\n",
        "\n",
        "        # Simulate true system from t=0 to t=110\n",
        "        lorenz = Lorenz63(sigma, rho, beta)\n",
        "        true_solution = odeint(lorenz.original_system, [x0, y0, z0], full_simulation_times)\n",
        "\n",
        "        # Extract only the observation period (t=100 to t=110)\n",
        "        obs_indices = (full_simulation_times >= observation_start_time)\n",
        "        observed_times = full_simulation_times[obs_indices]\n",
        "        observed_states = true_solution[obs_indices]\n",
        "\n",
        "        # Verify we have correct number of observation points\n",
        "        assert len(observed_times) == num_observations, \\\n",
        "               f\"Expected {num_observations} observations, got {len(observed_times)}\"\n",
        "\n",
        "        # Create observations (x-component only) during observation period\n",
        "        x_observed = np.column_stack((observed_times, observed_states[:, 0]))\n",
        "\n",
        "        # Simulate nudged system during observation period only\n",
        "        nudged_solution = odeint(lorenz.nudged_system, [0, 0, 0], observed_times, args=(x_observed, mu))\n",
        "\n",
        "        # Create training pairs (Algorithm 3.1)\n",
        "        for k in range(len(observed_times) - 1):\n",
        "            # Input: [w(t_k), I_M(u(t_k))]\n",
        "            current_state = nudged_solution[k]\n",
        "            current_obs = x_observed[k, 1]  # x(t_k)\n",
        "            input_pair = np.concatenate([current_state, [current_obs]])\n",
        "\n",
        "            # Output: w(t_{k+1})\n",
        "            next_state = nudged_solution[k + 1]\n",
        "\n",
        "            input_samples.append(input_pair)\n",
        "            output_samples.append(next_state)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    input_data = np.array(input_samples)\n",
        "    output_data = np.array(output_samples)\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Extract the portion of true_solution corresponding to observation_times\n",
        "    true_solution_obs_period = true_solution[obs_indices]\n",
        "\n",
        "    # Verification\n",
        "    print(\"\\n=== Verification ===\")\n",
        "    print(f\"Number of initial conditions (Ns): {num_reference_solutions}\")\n",
        "    print(f\"Observations per simulation: {num_observations - 1} (from {num_observations} time points)\")\n",
        "    expected_total_samples = num_reference_solutions * (num_observations - 1)\n",
        "    print(f\"Expected total samples: {expected_total_samples} (Ns × {num_observations - 1})\")\n",
        "    print(f\"Actual input_data shape: {input_data.shape} (should be ({expected_total_samples}, 4))\")\n",
        "    print(f\"Actual output_data shape: {output_data.shape} (should be ({expected_total_samples}, 3))\")\n",
        "\n",
        "    assert input_data.shape == (expected_total_samples, 4), \"Input data shape mismatch\"\n",
        "    assert output_data.shape == (expected_total_samples, 3), \"Output data shape mismatch\"\n",
        "\n",
        "    return input_data, output_data\n",
        "\n",
        "# Run the simulation\n",
        "input, nudged = simulate_lorenz_with_nudging()\n",
        "\n",
        "# crop to just the first N x N_s samples\n",
        "N = 15\n",
        "num_reference_solutions = 1000 # Define N_s here\n",
        "input = input[:num_reference_solutions * N]\n",
        "nudged = nudged[:num_reference_solutions * N]\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "# Algorithm 3.2: Online Usage of DNN for Data Assimilation #\n",
        "############################################################\n",
        "# 1: Initialize wDNN (t0) = 0 (or arbitrary)               #\n",
        "# 2: Observe IM (ui(t0))                                   #\n",
        "# 3: Set k = 0                                             #\n",
        "# 4: while Observations are available do                   #\n",
        "# 5:      wDNN (tk+1) = DNN (wDNN (tk), IM (ui(tk))        #\n",
        "# 6:      Observe IM (ui(tk+1))                            #\n",
        "# 7:      k = k + 1                                        #\n",
        "# 8: end while                                             #\n",
        "############################################################\n",
        "\n",
        "#define Lorenz 63 Model\n",
        "X_train, X_test, y_train, y_test = train_test_split(input, nudged, train_size=0.8)\n",
        "\n",
        "\n",
        "data = dde.data.Triple(X_train, y_train, X_test , y_test = y_test)\n",
        "net = dde.nn.FNN([4] + [50] * 3 + [3], \"tanh\", \"Glorot normal\")\n",
        "\n",
        "model_63 = dde.Model(data, net)\n",
        "model_63.compile(\"adam\", lr=0.001, metrics = [\"l2 relative error\"])\n",
        "checkpointer = dde.callbacks.ModelCheckpoint(\"./codes/model\", verbose=1, save_better_only= True)\n",
        "loss_history, train_state = model_63.train(epochs=2000, callbacks=[checkpointer])\n",
        "\n",
        "'''\n",
        "# Define checkpoint path\n",
        "save_dir = \"/content/checkpoints\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model_path = os.path.join(save_dir, \"model_63.h5\")  # HDF5 format\n",
        "'''\n",
        "#################################################################################\n",
        "#Create test data for graphs\n",
        "def test_lorenz_with_nudging():\n",
        "    # Parameters\n",
        "    sigma = 10.0\n",
        "    rho = 28.0\n",
        "    beta = 8/3\n",
        "    mu = 5.0  # Nudging parameter\n",
        "\n",
        "    input_test_samples = [] # stores <num_reference_solutions> many (x_bar, y_bar, z_bar, observed x) @ time t\n",
        "    output_test_samples = [] # stores <num_reference_solutions> many (x_bar, y_bar, z_bar) @ time t+1\n",
        "\n",
        "    for i in range(1):\n",
        "        # Display progress of generating solutions\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Generating reference solution {i}/{1}\")\n",
        "\n",
        "        # Generate random initial conditions\n",
        "        x0, y0, z0 = np.random.normal(loc=0, scale=50, size=3)\n",
        "\n",
        "        # Simulate true system\n",
        "        lorenz = Lorenz63(sigma, rho, beta)\n",
        "        true_solution = odeint(lorenz.original_system, [x0, y0, z0], observation_times)\n",
        "\n",
        "        # Create observations (x-component only)\n",
        "        x_observed = np.column_stack((observation_times, true_solution[:, 0])) # I_M(u^i(t_k))\n",
        "\n",
        "        # Simulate nudged system\n",
        "        nudged_solution = odeint(lorenz.nudged_system, [0, 0, 0], observation_times, args=(x_observed, mu)) # W^i(t_k)\n",
        "\n",
        "        # Create training pairs (Algorithm 3.1)\n",
        "        for k in range(len(observation_times) -  1):\n",
        "            # Input: [w(t_k), I_M(u(t_k))]\n",
        "            current_state = nudged_solution[k]\n",
        "            current_obs = x_observed[k, 1]  # x(t_k)\n",
        "            input_pair = np.concatenate([current_state, [current_obs]])\n",
        "\n",
        "            # Output: w(t_{k+1})\n",
        "            next_state = nudged_solution[k + 1]\n",
        "\n",
        "            input_test_samples.append(input_pair)\n",
        "            output_test_samples.append(next_state)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    input_test_data = np.array(input_test_samples)\n",
        "    output_test_data = np.array(output_test_samples)\n",
        "\n",
        "    return input_test_data, output_test_data\n",
        "\n",
        "# Run the test simulation for graphs\n",
        "original_test, nudged_test = test_lorenz_with_nudging()\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "# Load the saved model weights\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input, nudged, train_size=0.8)\n",
        "\n",
        "data = dde.data.Triple(X_train, y_train, X_test , y_test = y_test)\n",
        "net = dde.nn.FNN([4] + [50] * 3 + [3], \"tanh\", \"Glorot normal\")\n",
        "\n",
        "loaded_model = dde.Model(data, net)\n",
        "loaded_model.compile(\"adam\", lr=0.001, metrics = [\"l2 relative error\"])\n",
        "loaded_model.restore.restore(\"./codes/model-\"+ str(train_state.best_step) + \".ckpt\", verbose=1)\n",
        "\n",
        "\n",
        "# Get the initial state from the nudged solution of the test data\n",
        "initial_state = nudged_test[0]\n",
        "\n",
        "# Get the observed x values from the test data\n",
        "# We need the observed x at t_k for each step\n",
        "observed_x_test = original_test[:, 0]\n",
        "\n",
        "# Initialize the array to store the recursive predictions\n",
        "recursive_predictions = [initial_state]\n",
        "\n",
        "# Perform recursive prediction\n",
        "current_state = initial_state\n",
        "for k in range(len(observation_times) - 2): #-2 to make it the same length as others\n",
        "    # Construct the input for the current step: [w(t_k), I_M(u(t_k))]\n",
        "    # Use the predicted state from the previous step (or initial_state for the first step)\n",
        "    # and the observed x at the current time step t_k\n",
        "    current_input = np.concatenate([current_state, [observed_x_test[k]]])\n",
        "\n",
        "    # Reshape the input to match the model's expected input shape (batch_size, input_dim)\n",
        "    current_input = current_input.reshape(1, -1)\n",
        "\n",
        "    # Predict the next state: w(t_{k+1})\n",
        "    next_state_prediction = loaded_model.predict(current_input)\n",
        "\n",
        "    # Extract the predicted state (remove the batch dimension)\n",
        "    next_state_prediction = next_state_prediction[0]\n",
        "\n",
        "    # Store the prediction\n",
        "    recursive_predictions.append(next_state_prediction)\n",
        "\n",
        "    # Update the current state for the next iteration\n",
        "    current_state = next_state_prediction\n",
        "\n",
        "# Convert the list of predictions to a numpy array\n",
        "recursive_predictions = np.array(recursive_predictions)\n",
        "\n",
        "# Extract the components for plotting\n",
        "x_recursive = recursive_predictions[:, 0]\n",
        "y_recursive = recursive_predictions[:, 1]\n",
        "z_recursive = recursive_predictions[:, 2]\n",
        "t = observation_times[:len(original_test)]\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot x components\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(t, original_test[:, 0], 'b-', label='Original x')\n",
        "plt.plot(t, nudged_test[:, 0], 'r-', label = 'Nudging x')\n",
        "plt.plot(t, x_recursive, 'm--', label='Recursive Estimated x')\n",
        "plt.ylabel('x')\n",
        "plt.legend()\n",
        "\n",
        "# Plot y components\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(t, original_test[:, 1], 'b-', label='Original y')\n",
        "plt.plot(t, nudged_test[:, 1], 'r-', label = 'Nudging y')\n",
        "plt.plot(t, y_recursive, 'm--', label='Recursive Estimated y')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "\n",
        "# Plot z components\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(t, original_test[:, 2], 'b-', label='Original z')\n",
        "plt.plot(t, nudged_test[:, 2], 'r-', label = 'Nudging z')\n",
        "plt.plot(t, z_recursive, 'm--', label='Recursive Estimated z')\n",
        "plt.ylabel('z')\n",
        "plt.xlabel('Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle('Lorenz 63 System: Original vs Recursive Estimated Solutions')\n",
        "plt.show()"
      ]
    }
  ]
}